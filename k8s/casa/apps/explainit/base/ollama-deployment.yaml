apiVersion: apps/v1
kind: Deployment
metadata:
  name: explainit-ollama
  labels:
    app.kubernetes.io/name: explainit
    app.kubernetes.io/component: inference
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: explainit
      app.kubernetes.io/component: inference
  template:
    metadata:
      labels:
        app.kubernetes.io/name: explainit
        app.kubernetes.io/component: inference
    spec:
      initContainers:
        # Pull the model before main container starts
        - name: pull-model
          image: ollama/ollama:latest
          command:
            - /bin/sh
            - -c
            - |
              /bin/ollama serve &
              sleep 5
              ollama pull gemma3n:e4b
              pkill ollama
          resources:
            requests:
              memory: "512Mi"
              cpu: "100m"
          volumeMounts:
            - name: model-cache
              mountPath: /root/.ollama
      containers:
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - name: http
              containerPort: 11434
              protocol: TCP
          resources:
            requests:
              memory: "512Mi"
              cpu: "100m"
          volumeMounts:
            - name: model-cache
              mountPath: /root/.ollama
          readinessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
          livenessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 5
      volumes:
        - name: model-cache
          persistentVolumeClaim:
            claimName: explainit-ollama-model-cache

